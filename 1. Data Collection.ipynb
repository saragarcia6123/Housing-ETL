{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78926bc5-6dcd-4568-8968-0b76ea8e3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f9ce38e-3825-41df-968d-8fac15759904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Nottingham': {'search_url': 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E1019'},\n",
       "  'Newcastle-Under-Lyme': {'search_url': 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E982'},\n",
       "  'Loughborough': {'search_url': 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E871'},\n",
       "  'Lancaster': {'search_url': 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E769'},\n",
       "  'York': {'search_url': 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E1498'}},\n",
       " {'Nottingham': {'search_url': 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E1019'},\n",
       "  'Newcastle-Under-Lyme': {'search_url': 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E982'},\n",
       "  'Loughborough': {'search_url': 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E871'},\n",
       "  'Lancaster': {'search_url': 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E769'},\n",
       "  'York': {'search_url': 'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E1498'}})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = {\n",
    "    \"Nottingham\": \"1019\",\n",
    "    \"Newcastle-Under-Lyme\": \"982\",\n",
    "    \"Loughborough\": \"871\",\n",
    "    \"Lancaster\": \"769\",\n",
    "    \"York\": \"1498\"\n",
    "}\n",
    "\n",
    "def get_location_url(base_url, location_number):\n",
    "    params = {\"locationIdentifier\": f\"REGION^{location_number}\"}\n",
    "    return base_url + urlencode(params)\n",
    "\n",
    "base_url = \"https://www.rightmove.co.uk/property-{}/find.html?\"\n",
    "\n",
    "rents = {k: {'search_url': get_location_url(base_url.format('to-rent'), v)} for k, v in locations.items()}\n",
    "sales = {k: {'search_url': get_location_url(base_url.format('for-sale'), v)} for k, v in locations.items()}\n",
    "\n",
    "rents, sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c063636b-3276-42e5-b4a3-16177e685baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_results(session, url, pages=None):\n",
    "    \n",
    "    links = []\n",
    "    page = 0\n",
    "    index = 0\n",
    "\n",
    "    while pages is None or page < pages:  # None for all pages\n",
    "        res_url = f\"{url}&index={index}\"\n",
    "\n",
    "        async with session.get(res_url) as response:\n",
    "            if response.status == 400:\n",
    "                print(f\"Final page reached for URL {url}\")\n",
    "                break\n",
    "\n",
    "            response.raise_for_status()\n",
    "            html = await response.text()\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            # Extract property links\n",
    "            property_cards = soup.find_all(\"div\", class_=\"propertyCard-details\")[1:]  # exclude featured listing\n",
    "            property_links = [pc.find('a', class_=\"propertyCard-link\").get(\"href\") for pc in property_cards]\n",
    "            full_links = [f\"https://www.rightmove.co.uk{link}\" for link in property_links if link]\n",
    "            links.extend(full_links)\n",
    "\n",
    "            page += 1\n",
    "            index += len(property_cards)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0bdc602-fa7e-4b78-a9c4-a3aebdb54612",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_results(session, _dict, pages):\n",
    "    for k, v in _dict.items():\n",
    "        url = v['search_url']\n",
    "        results = await fetch_results(session, url, pages)\n",
    "        _dict[k]['links'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4858814d-6e8f-481f-b085-425508200bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_update_results(pages):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await asyncio.gather(\n",
    "            update_results(session, rents, pages),\n",
    "            update_results(session, sales, pages)\n",
    "        )\n",
    "await run_update_results(pages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e86491ec-f047-4f40-8957-62dad96893bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rents['Nottingham']['links']), len(sales['Nottingham']['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55fdf382-cd00-472e-9ccc-8143ded3721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_soup(url, session):\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\"\n",
    "    }\n",
    "    try:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            response.raise_for_status()\n",
    "            html = await response.text(encoding=\"utf-8\")\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        return soup\n",
    "        \n",
    "    except (aiohttp.ClientError, Exception) as e:\n",
    "        print(f\"Failed to fetch {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36af75b9-8668-4ae7-a4bc-ebf2597645e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_soups(session, _dict):\n",
    "    for k, v in _dict.items():\n",
    "        links = v['links']\n",
    "        soups = await asyncio.gather(*[fetch_soup(link, session) for link in links])\n",
    "        _dict[k]['soups'] = soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c7a2186-6f27-4fe3-b41e-1d9f190facca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_update_soups():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        await asyncio.gather(\n",
    "            update_soups(session, rents),\n",
    "            update_soups(session, sales)\n",
    "        )\n",
    "await run_update_soups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30fd7948-8338-4eea-b33c-f7dd87b4682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rents['Nottingham']['soups']), len(sales['Nottingham']['soups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aae886b8-ca9f-47a1-994f-10dfe7108118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_urls(data, base_folder):\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "    \n",
    "    for location, details in data.items():\n",
    "        location_folder = os.path.join(base_folder, location)\n",
    "        os.makedirs(location_folder, exist_ok=True)\n",
    "\n",
    "        # Save links\n",
    "        links_folder = os.path.join(location_folder, \"links\")\n",
    "        os.makedirs(links_folder, exist_ok=True)\n",
    "        with open(os.path.join(links_folder, \"links.json\"), \"w\") as f:\n",
    "            json.dump(details[\"links\"], f, indent=4)\n",
    "\n",
    "        # Save soups\n",
    "        soups_folder = os.path.join(location_folder, \"soups\")\n",
    "        os.makedirs(soups_folder, exist_ok=True)\n",
    "        for idx, soup in enumerate(details[\"soups\"], start=1):\n",
    "            soup_file = f\"soup_{idx}.html\"\n",
    "            with open(os.path.join(soups_folder, soup_file), \"w\") as f:\n",
    "                f.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f2da868-a68d-448a-8aab-e32fc4edb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_urls(rents, 'rent')\n",
    "save_urls(sales, 'sale')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
